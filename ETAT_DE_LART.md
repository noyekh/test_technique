# √âTAT DE L'ART ‚Äî RAG Juridique 2025-2026

**Synth√®se des recherches pour Legal RAG PoC v1.9**
**Date de compilation** : 11 janvier 2026
**Crit√®re de s√©lection** : Sources ‚â• 2025, priorit√© peer-reviewed

---

## Table des mati√®res

1. [Hallucinations en RAG l√©gal](#1-hallucinations-en-rag-l√©gal)
2. [Reranking : benchmarks et comparatifs](#2-reranking-benchmarks-et-comparatifs)
3. [Embeddings : √©tat de l'art 2025](#3-embeddings-√©tat-de-lart-2025)
4. [Multi-query expansion](#4-multi-query-expansion)
5. [Two-stage retrieval](#5-two-stage-retrieval)
6. [Seuils de relevance : anti-patterns et best practices](#6-seuils-de-relevance-anti-patterns-et-best-practices)
7. [Contextual Retrieval : validation critique](#7-contextual-retrieval-validation-critique)
8. [Citation verification](#8-citation-verification)
9. [LLMs pour le l√©gal](#9-llms-pour-le-l√©gal)
10. [Architectures production](#10-architectures-production)
11. [Analyse critique des sources](#11-analyse-critique-des-sources)
12. [R√©f√©rences compl√®tes](#12-r√©f√©rences-compl√®tes)

---

## 1. Hallucinations en RAG l√©gal

### 1.1 √âtude de r√©f√©rence : Stanford HAI (2025)

**Source principale** : Magesh, V. et al. "Hallucination-Free? Assessing the Reliability of Leading AI Legal Research Tools."
**Publication** : *Journal of Empirical Legal Studies*, Vol. 22, Issue 2, pp. 216-242, 2025
**URL** : https://onlinelibrary.wiley.com/doi/full/10.1111/jels.12413
**Statut** : ‚úÖ **Peer-reviewed** (publication acad√©mique de r√©f√©rence)

#### M√©thodologie

- 200+ requ√™tes l√©gales pr√©enregistr√©es
- Cohen's Œ∫ = 0.77 (accord inter-√©valuateurs substantiel)
- Inter-rater agreement : 85,4%
- √âvaluation par juristes qualifi√©s

#### R√©sultats cl√©s

| Syst√®me | Hallucination | Accuracy | Responsiveness |
|---------|---------------|----------|----------------|
| GPT-4 (baseline) | **58-82%** | ‚Äî | ‚Äî |
| Lexis+ AI | **17%** | 65% | 98% |
| Ask Practical Law AI | 17% | 19% | 60% |
| Westlaw AI-AR | **34%** | 42% | 93% |

#### Citations exactes

> "We find that legal RAG can reduce hallucinations compared to general-purpose AI systems (here, GPT-4), but hallucinations remain substantial, wide-ranging, and potentially insidious."

> "A citation can be 'hallucination-free' (the case exists) but still misleading (cited for the wrong proposition). These 'misgrounded' citations may be more dangerous than fabricated ones."

### 1.2 Harvey BigLaw Bench (2024-2025)

**Source** : Harvey AI Blog, "BigLaw Bench: Hallucinations"
**URL** : https://www.harvey.ai/blog/biglaw-bench-hallucinations
**Date** : Octobre 2024
**Statut** : ‚ö†Ô∏è Vendor (conflit d'int√©r√™ts)

| Mod√®le | Taux hallucination |
|--------|-------------------|
| Harvey Assistant | **0,2%** (1/500 claims) |
| Claude | 0,7% |
| ChatGPT | 1,3% |
| Gemini | 1,9% |

**‚ö†Ô∏è Mise en garde** : M√©thodologie diff√©rente de Stanford (t√¢ches grounded vs queries ouvertes). Le 0,2% n'a **pas √©t√© valid√© ind√©pendamment**.

### 1.3 VALS AI Legal Report (F√©vrier 2025)

**Source** : VALS AI Industry Report
**URL** : https://www.vals.ai/vlair
**Statut** : ‚úÖ Benchmark ind√©pendant

- Harvey : top performer 5/6 t√¢ches (94,8% Document Q&A)
- CoCounsel : excellent performance
- **LexisNexis s'est retir√© de l'√©valuation** ‚Äî signal pr√©occupant

### 1.4 AI Hallucination Cases Database

**Source** : Damien Charlotin (acad√©mique)
**URL** : https://www.damiencharlotin.com/hallucinations/
**Statut** : ‚úÖ Suivi ind√©pendant continu

- **764+ cas** document√©s globalement
- 324 cas tribunaux US
- √âvolution : ~2 cas/semaine (d√©but 2025) ‚Üí **2-3 cas/jour** (fin 2025)

---

## 2. Reranking : benchmarks et comparatifs

### 2.1 Agentset Reranker Leaderboard (Novembre 2025)

**Source** : Agentset
**URL** : https://agentset.ai/rerankers
**Date** : 25 novembre 2025
**M√©thodologie** : GPT-5 comme juge, datasets FiQA, SciFact, PG
**Statut** : ‚úÖ Benchmark ind√©pendant

| Rang | Mod√®le | ELO | nDCG@10 | Latence | Prix/1M |
|------|--------|-----|---------|---------|---------|
| 1 | Zerank 2 | **1654** | 0.223 | 565ms | $0.025 |
| 2 | Cohere Rerank 4 Pro | 1627 | 0.219 | 614ms | $0.050 |
| 3 | Zerank 1 | 1598 | 0.224 | 607ms | $0.025 |
| 4 | **Voyage rerank-2.5** | 1547 | **0.235** | 613ms | $0.050 |
| 6 | Voyage rerank-2.5-lite | 1528 | 0.226 | 616ms | $0.020 |
| 7 | Cohere Rerank 4 Fast | 1506 | 0.216 | 447ms | $0.050 |
| 11 | Jina Reranker v2 | 1306 | 0.193 | 746ms | $0.045 |

**Observation cl√©** : Voyage rerank-2.5 obtient le **meilleur nDCG@10** (0.235) malgr√© un ELO inf√©rieur. Pour le l√©gal, nDCG est plus pertinent que ELO.

### 2.2 LegalBench-RAG : Performance l√©gale sp√©cifique

**Source** : arXiv:2408.10343
**URL** : https://arxiv.org/abs/2408.10343
**Date** : Ao√ªt 2024
**Statut** : ‚úÖ Preprint acad√©mique (Stanford)

**Finding critique** :

> "Cohere rerank-english-v3.0 **underperformed versus no reranker at all** on legal precision and recall metrics."

**Corpus** : 6 858 paires Q&A, 79M+ caract√®res texte l√©gal
**Datasets** : CUAD, MAUD, ContractNLI, PrivacyQA

**‚ö†Ô∏è Gap** : rerank-2.5 et Cohere Rerank 4 non test√©s sur ce benchmark.

### 2.3 Pricing exact (Janvier 2026)

**Source** : https://docs.voyageai.com/docs/pricing

| Fournisseur | Mod√®le | Prix/1M tokens | Free tier |
|-------------|--------|----------------|-----------|
| Voyage AI | rerank-2.5 | $0.05 | **200M tokens** |
| Voyage AI | rerank-2.5-lite | $0.02 | 200M tokens |
| Cohere | Rerank 4 | $2.00/1K searches | Rate-limited |
| Jina | v2-multilingual | $0.045 | 10M tokens |

---

## 3. Embeddings : √©tat de l'art 2025

### 3.1 Voyage AI voyage-3-large (Janvier 2025)

**Source** : Voyage AI Blog
**URL** : https://blog.voyageai.com/2025/01/07/voyage-3-large/
**Date** : 7 janvier 2025
**Statut** : ‚ö†Ô∏è Vendor

#### Performance vs comp√©titeurs (nDCG@10, 100 datasets)

| Comparaison | Avantage voyage-3-large |
|-------------|-------------------------|
| vs OpenAI text-embedding-3-large (1024d) | **+10,58%** |
| vs OpenAI text-embedding-3-large (256d) | +11,47% |
| vs Cohere-v3-English | **+20,71%** |
| vs voyage-3 | +4,14% |
| vs voyage-law-2 | Sup√©rieur (claim vendor) |

### 3.2 Validations tierces

#### MongoDB Technical Blog (2025)

**URL** : https://medium.com/mongodb/how-to-choose-the-best-embedding-model-for-your-llm-application-2f65fcdfa58d
**Statut** : ‚úÖ Ind√©pendant

- **Latence** : voyage-3-large **89ms/chunk** vs text-embedding-3-large 311ms
- **Finding** : "voyage-3-large produces the strongest ranking by placing the most relevant results at the top"
- **M√©thodologie** : LLM-as-judge sans r√©v√©ler noms mod√®les

#### DEV.to/DataStax (2025)

**URL** : https://dev.to/datastax/the-best-embedding-models-for-information-retrieval-in-2025-3dp5
**Statut** : ‚úÖ Ind√©pendant

> "The just-released Voyage-3-large is the surprise leader in embedding relevance"

### 3.3 Harvey AI + Voyage partnership

**Source** : Harvey AI Blog
**URL** : https://www.harvey.ai/blog/harvey-partners-with-voyage-to-build-custom-legal-embeddings
**Date** : Mai 2024
**Statut** : ‚ö†Ô∏è Marketing (deux vendors)

- Custom voyage-law-2-harvey : fine-tuned 20 billion tokens US case law
- R√©duit mat√©riel non-pertinent de ~25% vs OpenAI/Google
- Corr√©lation humaine œÅ = 0.81-0.91

**‚ö†Ô∏è Note** : Ne compare pas voyage-law-2 √† voyage-3-large.

### 3.4 Pricing (Janvier 2026)

| Mod√®le | Prix/1M | Free tier | Dimensions | Context |
|--------|---------|-----------|------------|---------|
| voyage-3-large | $0.18 | **200M** | 2048 | 32K |
| text-embedding-3-large | $0.13 | $5 cr√©dits | 3072 | 8K |
| Cohere embed-v4 | $0.12 | Non sp√©cifi√© | 1536 | **128K** |

---

## 4. Multi-query expansion

### 4.1 √âtudes acad√©miques 2025

#### arXiv:2501.07391 ‚Äî "Enhancing RAG: Best Practices" (Janvier 2025)

**Source** : Universit√© de T√ºbingen
**Statut** : ‚úÖ Preprint acad√©mique (code public)

| M√©trique | Baseline | + Query Expansion | Gain |
|----------|----------|-------------------|------|
| FActScore TruthfulQA | 53,85% | 55,82% | +1,97pp |
| + Contrastive ICL | ‚Äî | **57,00%** | +3,15pp |

#### arXiv:2601.03258 ‚Äî FlashRank (Janvier 2025)

| M√©trique | Gain |
|----------|------|
| nDCG@10 (MS MARCO, BEIR, FinanceBench) | **+5,4%** |
| Generation accuracy | +6-8% |
| Context tokens reduction | -35% |
| Ablation : sans query expansion | **-5-6% recall** |

#### RAG-Fusion (arXiv:2402.03367, F√©vrier 2024)

| M√©trique | Gain |
|----------|------|
| Accuracy r√©ponses | +8-10% |
| Comprehensiveness (experts) | +30-40% |

### 4.2 Domaine l√©gal sp√©cifiquement

#### Stanford RegLab (CSLAW '25)

**URL** : https://reglab.github.io/legal-rag-benchmarks/
**Statut** : ‚úÖ Peer-reviewed

- **Gain Recall@10** : **+10 points de pourcentage** avec query expansion structur√©e

#### ACM ICMR '25 ‚Äî Multi-Round RAG

**URL** : https://dl.acm.org/doi/10.1145/3731715.3733451
**Statut** : ‚úÖ Peer-reviewed

| M√©trique | Single-round | Multi-round | Gain |
|----------|--------------|-------------|------|
| Recall | 57,33% | **78,67%** | +21,34pp |

### 4.3 Synth√®se des gains

| Technique | M√©trique | Gain | Source |
|-----------|----------|------|--------|
| Query expansion | Recall | +5-6% | FlashRank 2025 |
| RAG-Fusion | Accuracy | +8-10% | arXiv 2024 |
| Legal QE | Recall@10 | **+10pp** | Stanford 2025 |
| Multi-round Legal | Recall | **+21,34pp** | ACM 2025 |

---

## 5. Two-stage retrieval

### 5.1 Configurations document√©es

#### RankRAG (Nvidia, arXiv:2407.02485)

**Statut** : ‚úÖ Peer-reviewed

- **Recommandation** : top_k = 5-10 pour LLM final
- top-100 probl√©matique m√™me avec LLMs long-context
- Surpasse GPT-4 sur 9 benchmarks knowledge-intensive

#### RAG About It (2025)

**URL** : https://ragaboutit.com/adaptive-retrieval-reranking/

- Configuration enterprise : **top_k=100 ‚Üí rerank 50 ‚Üí output 5-10**
- Latence cible : reranking 100 docs < **300ms**
- Gain attendu : **+15-30% nDCG@5**

#### LRAGE (arXiv:2504.01840, Avril 2025)

- Configuration l√©gale : **top 3-5 documents** par d√©faut
- Test√© : Korean Bar Exam, LegalBench

### 5.2 Am√©liorations mesur√©es

**Source** : MyScale benchmark 2025

| M√©trique | Sans reranking | Avec reranking | Gain |
|----------|----------------|----------------|------|
| Hit Rate | 0.855 | 0.895 | **+4,7%** |
| MRR | 0.640 | 0.708 | **+10,5%** |

### 5.3 Configuration recommand√©e

| Use Case | Initial top_k | Post-rerank | Source |
|----------|---------------|-------------|--------|
| RAG standard | 25 | 3 | Pinecone |
| Enterprise | 100 | 5-10 | RAG About It |
| **Legal RAG** | **50-100** | **10-15** | Synth√®se |

---

## 6. Seuils de relevance : anti-patterns et best practices

### 6.1 Consensus acad√©mique : les seuils hardcod√©s sont un anti-pattern

**Source principale** : ≈ûakar & Emekci, "Optimizing RAG Thresholds", Cambridge University, 2025
**M√©thodologie** : 23 625 it√©rations de grid-search sur 4 domaines
**Statut** : ‚úÖ Preprint acad√©mique

#### R√©sultats cl√©s

Les seuils optimaux varient drastiquement selon le domaine :

| Domaine | Seuil optimal cosine | Impact d'un mauvais seuil |
|---------|---------------------|---------------------------|
| Financier (10Q) | 0.80 | -5,08% accuracy |
| Technique | 0.70 | -9,18% accuracy |
| M√©dical | 0.50 | -15,7% accuracy |
| **Juridique** | **0.70-0.75** | DRM >95% avec seuils standards |

**Finding critique** : Un seuil fixe de **0.5** laisse entre **76% et 100%** des requ√™tes sans contexte.

#### Citations exactes

> "Hardcoded thresholds create an illusion of control but fail when embedding models change, domains vary, or query distributions evolve."

### 6.2 Variation des scores selon les mod√®les d'embedding

Ni Voyage AI ni OpenAI ne fournissent de recommandations officielles de seuils. Les observations communautaires r√©v√®lent des √©carts majeurs :

| Mod√®le | Seuil sugg√©r√© | Plage observ√©e |
|--------|--------------|----------------|
| OpenAI ada-002 (legacy) | 0.75-0.85 | 0.50-0.95 |
| OpenAI text-embedding-3-small | **0.30-0.45** | 0.20-0.70 |
| OpenAI text-embedding-3-large | **0.27-0.40** | 0.15-0.65 |
| Voyage AI (g√©n√©ral) | 0.35-0.50 | Similar √† OpenAI v3 |
| **Contexte juridique** | **0.70-0.75** | Haute pr√©cision requise |

**Observation** : Le passage de ada-002 √† text-embedding-3 induit une **baisse de ~50%** des scores. Une m√™me requ√™te retourne 0.79 avec ada-002, **0.33** avec text-embedding-3-small.

### 6.3 Architecture recommand√©e : filtrer sur le reranker, pas sur cosine

**Source** : arXiv "Beyond Component Strength", Novembre 2025
**Statut** : ‚úÖ Preprint acad√©mique

**Finding critique** : L'adaptive thresholding seul **n'am√©liore rien** (40% d'abstention). C'est uniquement la **combinaison synergique** avec hybrid retrieval + reranking qui r√©duit l'abstention de 40% √† **2%**.

#### Pipeline production recommand√©

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Stage 1: Hybrid Retrieval (top-50 √† 200)                    ‚îÇ
‚îÇ   ‚Ä¢ Dense vector search (s√©mantique)                        ‚îÇ
‚îÇ   ‚Ä¢ BM25/sparse search (mots-cl√©s, codes, identifiants)     ‚îÇ
‚îÇ   ‚Ä¢ Reciprocal Rank Fusion (RRF) pour combinaison           ‚îÇ
‚îÇ   ‚Ä¢ ‚ö†Ô∏è PAS de seuil cosine ici                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Stage 2: Reranking (filtrer vers top-10 √† 20)               ‚îÇ
‚îÇ   ‚Ä¢ Cross-encoder reranker (Voyage, Cohere, BGE)            ‚îÇ
‚îÇ   ‚Ä¢ ‚úÖ Seuil sur score reranker (ex: >0.3 sur 0-1)          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Stage 3: Contexte final (top-3 √† 5 chunks au LLM)           ‚îÇ
‚îÇ   ‚Ä¢ √âviter le context stuffing                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 6.4 Seuils reranker recommand√©s

Les scores de reranker sont **calibr√©s** contrairement aux scores cosine bruts :

| Reranker | √âchelle | Seuil l√©gal recommand√© |
|----------|---------|------------------------|
| Voyage rerank-2.5 | 0-1 | **>0.3** |
| Cohere Rerank 4 | 0-1 | >0.3 |
| BGE Reranker v2 | 0-4 | >1.5-2.0 |

### 6.5 Techniques alternatives

| Technique | Impact | Complexit√© | Recommandation |
|-----------|--------|------------|----------------|
| **Reranker filtering** | **+20-50%** pr√©cision | Basse | ‚úÖ **Prioritaire** |
| Percentile filtering (top 10%) | +5-10% robustesse | Basse | ‚úÖ Simple fallback |
| Elbow detection (METEORA) | +10-20% | Haute | ‚ö†Ô∏è Complexe |
| Dynamic top-k | +15-30% | Haute | ‚ö†Ô∏è Complexe |

```python
# Percentile filtering (alternative simple)
threshold = np.percentile(scores, 90)  # Top 10%
filtered = [doc for doc in results if doc.score >= threshold]
```

### 6.6 Architectures production (Harvey, LexisNexis, Thomson Reuters)

Aucun de ces syst√®mes n'utilise de seuil de similarit√© cosine hardcod√© :

| Syst√®me | Approche |
|---------|----------|
| **Harvey AI** | LanceDB + sparse/dense, reranker filtrage |
| **LexisNexis** | GraphRAG + Shepard's Knowledge Graph |
| **Thomson Reuters** | Recherche f√©d√©r√©e, mod√®les Claude par complexit√© |

### 6.7 Verdict et recommandation

| Pratique | √âvaluation |
|----------|------------|
| Seuil cosine hardcod√© (ex: 0.35) | ‚ùå **Anti-pattern** |
| Seuil cosine dynamique (percentile) | ‚ö†Ô∏è Acceptable fallback |
| **Filtrage sur score reranker** | ‚úÖ **Best practice** |
| Hybrid + Rerank + Reranker threshold | ‚úÖ **Production-ready** |

**Impl√©mentation v1.9.1** : Suppression du seuil cosine `min_relevance`, filtrage uniquement via reranker `top_n` + seuil optionnel sur score reranker.

---

## 7. Contextual Retrieval : validation critique

### 7.1 Claims originaux (Anthropic, Septembre 2024)

**Source** : https://www.anthropic.com/news/contextual-retrieval

| Configuration | R√©duction √©checs |
|---------------|------------------|
| Contextual Embeddings seuls | -35% |
| + Contextual BM25 | -49% |
| + Reranking | **-67%** |

### 7.2 Tentatives de validation

#### arXiv:2504.19754 ‚Äî "Reconstructing Context" (Avril 2025)

**Source** : Universit√© de Bologna, ECIR 2025 Workshop
**Statut** : ‚úÖ Acad√©mique

**Findings** :
- ‚úÖ "Contextual retrieval preserves semantic coherence more effectively"
- ‚ùå **Non-r√©plication du -67%**
- ‚ö†Ô∏è "Neither technique offers a definitive solution" ‚Äî trade-offs significatifs

#### LlamaIndex Implementation

**URL** : https://docs.llamaindex.ai/en/stable/examples/cookbooks/contextual_retrieval/

> "Results vary ‚Äî much depends on queries, chunk size, chunk overlap, and other variables"

**Non-r√©plication** des pourcentages sp√©cifiques.

### 7.3 Verdict

| Aspect | √âvaluation |
|--------|------------|
| Technique valide ? | ‚úÖ Am√©liore retrieval |
| -67% r√©pliqu√© ? | ‚ùå **Non** |
| Datasets publi√©s ? | ‚ùå Non |
| Recommandation | ‚ö†Ô∏è Utiliser avec pr√©caution |

### 7.4 Alternatives 2025

| Technique | Source | Avantage |
|-----------|--------|----------|
| **Late Chunking** | Jina AI (arXiv:2409.04701) | Pas d'appels LLM suppl√©mentaires |
| LongRAG | Multiple | Exploite LLMs long-context |
| RAG-Fusion | arXiv:2402.03367 | Multi-query + RRF |

---

## 8. Citation verification

### 8.1 Techniques acad√©miques peer-reviewed

#### CiteFix (ACL 2025 Industry Track)

**URL** : https://aclanthology.org/2025.acl-industry.23/
**Date** : Juin 2025
**Statut** : ‚úÖ Peer-reviewed

| M√©trique | Valeur |
|----------|--------|
| Am√©lioration relative accuracy | **+15,46%** |
| Baseline accuracy citations LLM | ~74% |
| Permet shift vers mod√®les | 12x moins chers, 3x plus rapides |

#### VeriCite (SIGIR-AP 2025)

**URL** : https://arxiv.org/abs/2510.11394
**Date** : Octobre 2025

- Framework 3 √©tapes : g√©n√©ration ‚Üí v√©rification NLI ‚Üí refinement
- Code public : github.com/QianHaosheng/VeriCite

#### HalluGraph (D√©cembre 2025)

**URL** : https://arxiv.org/pdf/2512.01659

- Framework graph-th√©orique pour domaine l√©gal
- Entity Grounding + Relation Preservation
- Audit trail explicable

### 8.2 Impl√©mentations production

| Syst√®me | Technique | Performance |
|---------|-----------|-------------|
| **Harvey** | Knowledge Source ID | >95% accuracy |
| LexisNexis | 5 checkpoints/prompt | 17% hallucinations (Stanford) |
| Westlaw | KeyCite + checker | 34% hallucinations (Stanford) |

### 8.3 Synth√®se gains

| Technique | R√©duction | Source |
|-----------|-----------|--------|
| RAG vs LLM g√©n√©ral | 58-82% ‚Üí 17-33% | Stanford 2025 |
| CiteFix post-processing | **+15,46% accuracy** | ACL 2025 |
| NLI verification | +23% groundedness | TechRxiv 2025 |

---

## 9. LLMs pour le l√©gal

### 9.1 GPT-4.1-mini

**Release** : 14 avril 2025
**Context** : 1M tokens
**Pricing** : $0.40/M input, $1.60/M output

#### Benchmarks disponibles

**‚ö†Ô∏è Gap critique** : GPT-4.1-mini **non benchmark√©** sur LegalBench (Vals.ai donn√©es incompl√®tes)

**LEXam Benchmark** (arXiv:2505.12864, 2025)

| Mod√®le | Score | MCQ Accuracy |
|--------|-------|--------------|
| Gemini-2.5-Pro | **82,2** | ‚Äî |
| GPT-4.1 | 68,2 | 54,4% |
| GPT-4o | 66,2 | ‚Äî |

#### Validations partenaires

| Partenaire | Claim | Statut |
|------------|-------|--------|
| Thomson Reuters | +17% multi-doc legal analysis | ‚ö†Ô∏è Non valid√© tiers |
| Blue J Tax | +53% accuracy cas fiscaux difficiles | ‚ö†Ô∏è Non valid√© tiers |

### 9.2 Leaders LegalBench (D√©cembre 2025)

**Source** : Vals.ai

| Rang | Mod√®le | Score |
|------|--------|-------|
| 1 | Gemini 3 Pro | **87,04%** |
| 2 | Gemini 3 Flash | 86,86% |
| 3 | GPT 5 | 86,02% |
| 4 | GPT 5.1 | 85,68% |

---

## 10. Architectures production

### 10.1 Harvey AI (2025)

**Sources** : Harvey Blog, VALS Report

| Composant | Choix |
|-----------|-------|
| Embeddings | Custom voyage-law-2-harvey |
| Citation verification | Knowledge Source ID (>95%) |
| Evaluation | BigLaw Bench (74% answer quality) |
| Partnership | LexisNexis (Ask LexisNexis¬Æ) |

### 10.2 Thomson Reuters CoCounsel (Ao√ªt 2025)

**Source** : https://www.lawnext.com/2025/08/thomson-reuters-launches-cocounsel-legal-with-agentic-ai-and-deep-research-capabilities

- **Deep Research** : AI agentic multi-step
- KeyCite integration
- Hallucination checker int√©gr√©

### 10.3 LexisNexis Lexis+ AI

- 5 checkpoints minimum par prompt
- Shepard's¬Æ Citations Service
- **Stanford** : 17% hallucination rate (meilleur test√©)
- Retrait du benchmark VALS AI ‚Äî signal pr√©occupant

---

## 11. Analyse critique des sources

### 11.1 Matrice de fiabilit√©

| Source | Type | Peer-review | Conflit | Fiabilit√© |
|--------|------|-------------|---------|-----------|
| Stanford HAI/JELS 2025 | Journal | ‚úÖ | ‚ùå | **Haute** |
| LegalBench-RAG arXiv | Preprint | ‚ö†Ô∏è | ‚ùå | **Haute** |
| CiteFix ACL 2025 | Conf√©rence | ‚úÖ | ‚ùå | **Haute** |
| Agentset Leaderboard | Benchmark | ‚ö†Ô∏è | ‚ùå | **Haute** |
| MongoDB Blog | Tutorial | ‚ùå | ‚ùå | Moyenne |
| Voyage AI Blog | Marketing | ‚ùå | ‚ö†Ô∏è | Moyenne |
| Harvey AI Blog | Marketing | ‚ùå | ‚ö†Ô∏è | **Faible** |
| Anthropic Blog | Research | ‚ùå | ‚ö†Ô∏è | Moyenne |

### 11.2 Affirmations non valid√©es

| Affirmation | Source | Statut |
|-------------|--------|--------|
| -67% Contextual Retrieval | Anthropic | ‚ùå **Non r√©pliqu√©** |
| 0,2% hallucinations Harvey | Harvey | ‚ùå **Non valid√©** |
| +17% legal GPT-4.1 | Thomson Reuters | ‚ùå **Non valid√©** |
| voyage-3-large > voyage-law-2 | Voyage AI | ‚ö†Ô∏è **Pas de test tiers** |

### 11.3 Gaps critiques identifi√©s

| Domaine | Gap | Priorit√© |
|---------|-----|----------|
| Reranking l√©gal | Aucun benchmark 3 mod√®les sur m√™mes donn√©es l√©gales | üî¥ |
| GPT-4.1-mini | Non benchmark√© LegalBench | üî¥ |
| voyage-law-2 vs v3-large | Aucune validation tierce | üî¥ |
| Contextual Retrieval | -67% non r√©pliqu√© | üü° |

---

## 12. R√©f√©rences compl√®tes

### Peer-reviewed (priorit√© maximale)

1. Magesh, V. et al. "Hallucination-Free? Assessing the Reliability of Leading AI Legal Research Tools." *JELS*, Vol. 22(2), 2025.
   https://onlinelibrary.wiley.com/doi/full/10.1111/jels.12413

2. "CiteFix: Enhancing RAG Accuracy Through Post-Processing Citation Correction." *ACL 2025 Industry Track*.
   https://aclanthology.org/2025.acl-industry.23/

3. "LegalBench-RAG: A Benchmark for RAG in the Legal Domain." arXiv:2408.10343, 2024.
   https://arxiv.org/abs/2408.10343

4. "Enhancing RAG: A Study of Best Practices." arXiv:2501.07391, Janvier 2025.
   https://arxiv.org/abs/2501.07391

5. "Two-Stage Retrieval: FlashRank Reranking and Query Expansion." arXiv:2601.03258, Janvier 2025.
   https://arxiv.org/abs/2601.03258

6. "RankRAG: Unifying Context Ranking with RAG in LLMs." arXiv:2407.02485, Juillet 2024.
   https://arxiv.org/abs/2407.02485

7. "VeriCite: Towards Reliable Citations in RAG." SIGIR-AP 2025.
   https://arxiv.org/abs/2510.11394

8. "HalluGraph: Auditable Hallucination Detection for Legal RAG." arXiv:2512.01659, D√©cembre 2025.
   https://arxiv.org/pdf/2512.01659

9. "LEXam: Benchmarking Legal Reasoning on 340 Law Exams." arXiv:2505.12864, 2025.
   https://arxiv.org/abs/2505.12864

10. "Multi-Round RAG for Legal Document Analysis." ACM ICMR '25.
    https://dl.acm.org/doi/10.1145/3731715.3733451

11. ≈ûakar & Emekci. "Optimizing RAG Thresholds." Cambridge University, 2025.
    Grid-search sur 23 625 it√©rations.

12. Krishnan. "Beyond Component Strength: Synergistic Integration and Adaptive Calibration in Multi-Agent RAG Systems." arXiv, Novembre 2025.
    https://arxiv.org/abs/2511.21729

### Benchmarks ind√©pendants

13. Agentset. "Reranker Leaderboard." Novembre 2025.
    https://agentset.ai/rerankers

12. VALS AI. "Legal AI Report." F√©vrier 2025.
    https://www.vals.ai/vlair

13. Stanford RegLab. "Legal RAG Benchmarks." CSLAW '25.
    https://reglab.github.io/legal-rag-benchmarks/

14. Charlotin, D. "AI Hallucination Cases Database."
    https://www.damiencharlotin.com/hallucinations/

### √âvaluations tierces

15. MongoDB. "How to Choose the Best Embedding Model." 2025.
    https://medium.com/mongodb/how-to-choose-the-best-embedding-model-for-your-llm-application-2f65fcdfa58d

16. DEV.to/DataStax. "Best Embedding Models 2025."
    https://dev.to/datastax/the-best-embedding-models-for-information-retrieval-in-2025-3dp5

17. RAG About It. "Adaptive Retrieval Reranking." 2025.
    https://ragaboutit.com/adaptive-retrieval-reranking/

### Vendor (utiliser avec pr√©caution)

18. Voyage AI. "voyage-3-large." Janvier 2025.
    https://blog.voyageai.com/2025/01/07/voyage-3-large/

19. Voyage AI. "Pricing." D√©cembre 2025.
    https://docs.voyageai.com/docs/pricing

20. Anthropic. "Contextual Retrieval." Septembre 2024.
    https://www.anthropic.com/news/contextual-retrieval

21. Harvey AI. "BigLaw Bench: Hallucinations." Octobre 2024.
    https://www.harvey.ai/blog/biglaw-bench-hallucinations

22. Harvey AI. "Voyage Partnership." Mai 2024.
    https://www.harvey.ai/blog/harvey-partners-with-voyage-to-build-custom-legal-embeddings

23. OpenAI. "GPT-4.1 Release." Avril 2025.
    https://openai.com/index/gpt-4-1/

### Impl√©mentations

24. LlamaIndex. "Contextual Retrieval Cookbook."
    https://docs.llamaindex.ai/en/stable/examples/cookbooks/contextual_retrieval/

25. Thomson Reuters. "CoCounsel Legal." Ao√ªt 2025.
    https://www.lawnext.com/2025/08/thomson-reuters-launches-cocounsel-legal-with-agentic-ai-and-deep-research-capabilities

---

*Document de recherche ‚Äî Legal RAG PoC v1.9*
*Derni√®re mise √† jour : 11 janvier 2026*
*Prochaine r√©vision recommand√©e : Avril 2026 (√©volution rapide du domaine)*
